input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}
	file {
		path => "/usr/share/sample-data/*.log"
		start_position => "beginning"   # Start reading from the beginning of the file
		# sincedb_path => "/dev/null"
		# sincedb_clean_after => "1 hour" # Clean up old sincedb files
		# codec => "json"                 # Use json codec if your log files are in JSON format
  }
}

filter {
  grok {
    match => {
      "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{WORD:loglevel} %{GREEDYDATA:class} - %{GREEDYDATA:message}"
    }
	overwrite => [ "message" ]
  }

  # Optional: Convert the timestamp field to a date type in Elasticsearch
  date {
    match => ["timestamp", "ISO8601"]
  }
}
## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
	}
}
